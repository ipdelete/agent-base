# ==============================================================================
# Agent Settings
# ==============================================================================
AGENT_DATA_DIR=~/.agent
AGENT_LOG_LEVEL=info

# ==============================================================================
# LLM Provider Configuration
# ==============================================================================
# Supported providers: local, openai, anthropic, azure, foundry, gemini
# Recommended: local (free, runs with Docker Desktop)
# Optional: Override the default model for any provider
LLM_PROVIDER=local


# ==============================================================================
# Local Provider Configuration (when LLM_PROVIDER=local)
# ==============================================================================
# Docker Desktop Model Runner with OpenAI-compatible API
# Requires: Docker Desktop with Model Runner enabled
# Setup:
#   1. docker desktop enable model-runner --tcp=12434
#   2. docker model pull phi4
# Note: Use full model ID from 'docker model list' or Docker Desktop UI
# Recommended: phi4 for speed, or qwen3 for tool calling accuracy
LOCAL_BASE_URL=http://localhost:12434/engines/llama.cpp/v1
AGENT_MODEL=ai/phi4

# ==============================================================================
# OpenAI Configuration (when LLM_PROVIDER=openai)
# ==============================================================================
# OPENAI_API_KEY=your-api-key-here

# ==============================================================================
# Anthropic Configuration (when LLM_PROVIDER=anthropic)
# ==============================================================================
# ANTHROPIC_API_KEY=your-api-key-here

# ==============================================================================
# Google Gemini Configuration (when LLM_PROVIDER=gemini)
# ==============================================================================
# Gemini Developer API (API key authentication)
# Get your API key from: https://aistudio.google.com/apikey
# GEMINI_API_KEY=your-api-key-here

# ==============================================================================
# Azure OpenAI Configuration (when LLM_PROVIDER=azure)
# ==============================================================================
# Requires: az login OR AZURE_OPENAI_API_KEY
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name
# AZURE_OPENAI_VERSION=2024-08-01-preview
# AZURE_OPENAI_API_KEY=your-api-key-here

# ==============================================================================
# Azure AI Foundry Configuration (when LLM_PROVIDER=foundry)
# ==============================================================================
# Requires: az login (uses AzureCliCredential)
# AZURE_PROJECT_ENDPOINT=https://your-project.services.ai.azure.com/api/projects/your-project-id

# ==============================================================================
# System Prompt Configuration
# ==============================================================================
# System prompt loading priority:
# 1. AGENT_SYSTEM_PROMPT (explicit override) - use this variable
# 2. ~/.agent/system.md (user's default) - create this file to customize globally
# 3. Agent default (src/agent/prompts/system.md) - fallback if above don't exist
#
# AGENT_SYSTEM_PROMPT=/path/to/prompt.md

# ==============================================================================
# Observability Configuration (OpenTelemetry)
# ==============================================================================
# Enable OpenTelemetry instrumentation for traces, logs, and metrics
# ENABLE_OTEL=true
# OTLP_ENDPOINT=http://localhost:4317

# ==============================================================================
# Observability Configuration (Foundry)
# ==============================================================================
# When Application Insights is connected to an Azure AI Foundry project.
# APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=xxx;IngestionEndpoint=https://xxx.in.applicationinsights.azure.com/